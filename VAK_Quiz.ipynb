{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anushkaghei/V.A.R.K/blob/main/VAK_Quiz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuKlphuImFSN"
      },
      "source": [
        "\n",
        "  * Create a deep neural network that performs multi-class classification.\n",
        "  * Tune the deep neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxj8yVh4mFl5"
      },
      "source": [
        "## The Dataset\n",
        "This is a multi-class classification problem with 3 output classes, one for each learning style."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n9_cTveKmse"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "# The following line improves formatting when ouputting NumPy arrays.\n",
        "np.set_printoptions(linewidth = 200)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_TaJhU4KcuY"
      },
      "source": [
        "## Load the dataset\n",
        "\n",
        "`tf.keras` provides a set of convenience functions for loading well-known datasets. Each of these convenience functions does the following:\n",
        "\n",
        "* Loads both the training set and the test set.\n",
        "* Separates each set into features and labels.\n",
        "\n",
        "The relevant convenience function for MNIST is called `mnist.load_data()`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "744ZpZ47aPFx",
        "outputId": "19a3af6e-d75f-48e0-f9b0-d13a6320142b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZlvdpyYKx7V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "83dbe546-abca-40d3-ff37-c9ca4d360a28"
      },
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Kodikon/datasets/vak_quiz_data.csv\")\n",
        "display(df)\n",
        "df.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      Gender  Age  Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  Q11  Q12  Q13  \\\n",
              "0          0   16   3   3   4   3   2   4   3   3   2    3    4    2    2   \n",
              "1          0   16   5   4   4   4   3   3   2   4   3    4    3    4    3   \n",
              "2          0   18   3   4   3   3   4   2   4   3   2    2    3    2    3   \n",
              "3          0   21   1   3   3   4   4   2   2   2   2    2    4    4    4   \n",
              "4          1   21   4   4   4   5   5   4   4   3   4    4    5    5    5   \n",
              "...      ...  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...   \n",
              "1205       0   17   2   3   3   4   4   3   3   3   3    3    4    4    4   \n",
              "1206       0   18   5   2   4   3   3   3   3   3   3    5    3    5    4   \n",
              "1207       0   19   4   4   5   3   5   5   4   4   5    3    4    3    5   \n",
              "1208       1   17   2   3   5   4   4   4   4   5   4    3    4    5    2   \n",
              "1209       0   16   4   3   3   5   3   4   3   4   3    3    3    4    1   \n",
              "\n",
              "      Q14  Q15  Style  \n",
              "0       3    3      2  \n",
              "1       4    4      1  \n",
              "2       3    3      1  \n",
              "3       4    5      2  \n",
              "4       3    3      1  \n",
              "...   ...  ...    ...  \n",
              "1205    4    4      2  \n",
              "1206    3    3      2  \n",
              "1207    5    5      2  \n",
              "1208    3    5      0  \n",
              "1209    4    3      1  \n",
              "\n",
              "[1210 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44fb92b6-af66-4a80-b213-53a28123454b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7</th>\n",
              "      <th>Q8</th>\n",
              "      <th>Q9</th>\n",
              "      <th>Q10</th>\n",
              "      <th>Q11</th>\n",
              "      <th>Q12</th>\n",
              "      <th>Q13</th>\n",
              "      <th>Q14</th>\n",
              "      <th>Q15</th>\n",
              "      <th>Style</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1205</th>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1206</th>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1207</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1210 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44fb92b6-af66-4a80-b213-53a28123454b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44fb92b6-af66-4a80-b213-53a28123454b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44fb92b6-af66-4a80-b213-53a28123454b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1210 entries, 0 to 1209\n",
            "Data columns (total 18 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   Gender  1210 non-null   int64\n",
            " 1   Age     1210 non-null   int64\n",
            " 2   Q1      1210 non-null   int64\n",
            " 3   Q2      1210 non-null   int64\n",
            " 4   Q3      1210 non-null   int64\n",
            " 5   Q4      1210 non-null   int64\n",
            " 6   Q5      1210 non-null   int64\n",
            " 7   Q6      1210 non-null   int64\n",
            " 8   Q7      1210 non-null   int64\n",
            " 9   Q8      1210 non-null   int64\n",
            " 10  Q9      1210 non-null   int64\n",
            " 11  Q10     1210 non-null   int64\n",
            " 12  Q11     1210 non-null   int64\n",
            " 13  Q12     1210 non-null   int64\n",
            " 14  Q13     1210 non-null   int64\n",
            " 15  Q14     1210 non-null   int64\n",
            " 16  Q15     1210 non-null   int64\n",
            " 17  Style   1210 non-null   int64\n",
            "dtypes: int64(18)\n",
            "memory usage: 170.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "churn_df = df[['Gender', 'Age', 'Q1','Q2','Q3','Q4','Q5','Q6','Q7','Q8','Q9','Q10','Q11','Q12','Q13','Q14','Q15','Style']]\n",
        "churn_df.head()"
      ],
      "metadata": {
        "id": "GUPUk74h5XlQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "90b12898-6df5-474d-f9ea-58dd50cd9c52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Gender  Age  Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  Q11  Q12  Q13  Q14  \\\n",
              "0       0   16   3   3   4   3   2   4   3   3   2    3    4    2    2    3   \n",
              "1       0   16   5   4   4   4   3   3   2   4   3    4    3    4    3    4   \n",
              "2       0   18   3   4   3   3   4   2   4   3   2    2    3    2    3    3   \n",
              "3       0   21   1   3   3   4   4   2   2   2   2    2    4    4    4    4   \n",
              "4       1   21   4   4   4   5   5   4   4   3   4    4    5    5    5    3   \n",
              "\n",
              "   Q15  Style  \n",
              "0    3      2  \n",
              "1    4      1  \n",
              "2    3      1  \n",
              "3    5      2  \n",
              "4    3      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e27aec1-90e6-4f76-9c9d-489c7fe0290c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7</th>\n",
              "      <th>Q8</th>\n",
              "      <th>Q9</th>\n",
              "      <th>Q10</th>\n",
              "      <th>Q11</th>\n",
              "      <th>Q12</th>\n",
              "      <th>Q13</th>\n",
              "      <th>Q14</th>\n",
              "      <th>Q15</th>\n",
              "      <th>Style</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e27aec1-90e6-4f76-9c9d-489c7fe0290c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e27aec1-90e6-4f76-9c9d-489c7fe0290c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e27aec1-90e6-4f76-9c9d-489c7fe0290c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.asanyarray(churn_df[['Gender', 'Age', 'Q1','Q2','Q3','Q4','Q5','Q6','Q7','Q8','Q9','Q10','Q11','Q12','Q13','Q14','Q15']])\n",
        "x[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRa76T4gBt9r",
        "outputId": "a53bb8d7-2574-4173-9875-7832d596caa4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0, 16,  3,  3,  4,  3,  2,  4,  3,  3,  2,  3,  4,  2,  2,  3,  3],\n",
              "       [ 0, 16,  5,  4,  4,  4,  3,  3,  2,  4,  3,  4,  3,  4,  3,  4,  4],\n",
              "       [ 0, 18,  3,  4,  3,  3,  4,  2,  4,  3,  2,  2,  3,  2,  3,  3,  3],\n",
              "       [ 0, 21,  1,  3,  3,  4,  4,  2,  2,  2,  2,  2,  4,  4,  4,  4,  5],\n",
              "       [ 1, 21,  4,  4,  4,  5,  5,  4,  4,  3,  4,  4,  5,  5,  5,  3,  3]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.asanyarray(df['Style'])\n",
        "y [0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-ke_ScK94Tb",
        "outputId": "53d5a806-7b0c-4aa9-812d-86c744141cd6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 1, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "x = preprocessing.StandardScaler().fit(x).transform(x)\n",
        "# std value = (x-myu)/sigma where myu is mean, sigma is variance\n",
        "x[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYXIZ-CY-EEh",
        "outputId": "7526c655-5a25-4fa9-c1de-384439b323cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.01835015, -1.23562404, -0.26079255, -0.46636597,  0.63459284, -0.28474856, -1.10624671,  0.51640379, -0.42801861, -0.31019636, -1.20461633, -0.36921342,  0.42544364, -1.52046716,\n",
              "        -1.45748557, -0.39122214, -0.51705101],\n",
              "       [-1.01835015, -1.23562404,  1.53215621,  0.55039588,  0.63459284,  0.66180572, -0.21029054, -0.47384753, -1.40335292,  0.61428049, -0.25874627,  0.58947379, -0.46211982,  0.39495737,\n",
              "        -0.56499694,  0.57288945,  0.49203241],\n",
              "       [-1.01835015, -0.28755486, -0.26079255,  0.55039588, -0.35619082, -0.28474856,  0.68566563, -1.46409886,  0.5473157 , -0.31019636, -1.20461633, -1.32790064, -0.46211982, -1.52046716,\n",
              "        -0.56499694, -0.39122214, -0.51705101],\n",
              "       [-1.01835015,  1.13454889, -2.0537413 , -0.46636597, -0.35619082,  0.66180572,  0.68566563, -1.46409886, -1.40335292, -1.23467322, -1.20461633, -1.32790064,  0.42544364,  0.39495737,\n",
              "         0.3274917 ,  0.57288945,  1.50111583],\n",
              "       [ 0.98198051,  1.13454889,  0.63568183,  0.55039588,  0.63459284,  1.60836   ,  1.5816218 ,  0.51640379,  0.5473157 , -0.31019636,  0.68712379,  0.58947379,  1.3130071 ,  1.35266964,\n",
              "         1.21998033, -0.39122214, -0.51705101]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size=0.2, random_state=4)\n",
        "print ('Train set:', x_train.shape,  y_train.shape)\n",
        "print ('Test set:', x_test.shape,  y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-QP4N0FChJE",
        "outputId": "7fcc2811-77ac-468e-ea31-d41ae1ced631"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: (968, 17) (968,)\n",
            "Test set: (242, 17) (242,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfQkr3hxJGXU"
      },
      "source": [
        "* `x_train` contains the training set's features.\n",
        "* `y_train` contains the training set's labels.\n",
        "* `x_test` contains the test set's features.\n",
        "* `y_test` contains the test set's labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoOhpjkeCL8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea51534-9358-4906-ed2d-04afdca19c26"
      },
      "source": [
        "# Output example #3 of the training set.\n",
        "x_train[3]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.01835015, -1.23562404,  0.63568183, -0.46636597,  0.63459284, -0.28474856, -0.21029054,  0.51640379, -0.42801861, -0.31019636, -0.25874627, -0.36921342,  0.42544364,  0.39495737,\n",
              "       -0.56499694,  0.57288945,  0.49203241])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBWRF6CStuNA"
      },
      "source": [
        "## Define a plotting function\n",
        "\n",
        "The following function plots an accuracy curve:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF0BFRXTOeR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef9f02a1-bebd-4b64-8074-d490ddec71c1"
      },
      "source": [
        "#@title Define the plotting function\n",
        "def plot_curve(epochs, hist, list_of_metrics):\n",
        "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
        "  # list_of_metrics should be one of the names shown in:\n",
        "  # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics  \n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Value\")\n",
        "\n",
        "  for m in list_of_metrics:\n",
        "    x = hist[m]\n",
        "    plt.plot(epochs[1:], x[1:], label=m)\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "print(\"Loaded the plot_curve function.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the plot_curve function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3014ezH3C7jT"
      },
      "source": [
        "## Create a deep neural net model\n",
        "\n",
        "The `create_model` function defines the topography of the deep neural net, specifying the following:\n",
        "\n",
        "* The number of [layers](https://developers.google.com/machine-learning/glossary/#layer) in the deep neural net.\n",
        "* The number of [nodes](https://developers.google.com/machine-learning/glossary/#node) in each layer.\n",
        "* Any [regularization](https://developers.google.com/machine-learning/glossary/#regularization) layers.\n",
        "\n",
        "The `create_model` function also defines the [activation function](https://developers.google.com/machine-learning/glossary/#activation_function) of each layer.  The activation function of the output layer is [softmax](https://developers.google.com/machine-learning/glossary/#softmax), which will yield 3 different outputs for each example. Each of the 3 outputs provides the probability that the input example is a certain learning style.\n",
        "\n",
        "**Note:** Unlike several of the recent Colabs, this exercise does not define feature columns or a feature layer.  Instead, the model will train on the NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pedD5GhlDC-y",
        "cellView": "both"
      },
      "source": [
        "def create_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "  \n",
        "  # All models in this course are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Define the first hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "  # Define a dropout regularization layer. \n",
        "  model.add(tf.keras.layers.Dropout(rate=0.5))\n",
        "\n",
        "  # Define the output layer. The units parameter is set to 3 because\n",
        "  # the model must choose among 3 possible output values (representing\n",
        "  # the digits from 0-2, inclusive).\n",
        "  #\n",
        "  # Don't change this layer.\n",
        "  model.add(tf.keras.layers.Dense(units=3, activation='softmax'))     \n",
        "                           \n",
        "  # Construct the layers into a model that TensorFlow can execute.  \n",
        "  # Notice that the loss function for multi-class classification\n",
        "  # is different than the loss function for binary classification.  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model    \n",
        "\n",
        "\n",
        "def train_model(model, train_features, train_label, epochs,\n",
        "                batch_size=None, validation_split=0.1):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=True, \n",
        "                      validation_split=validation_split)\n",
        " \n",
        "  # To track the progression of training, gather a snapshot\n",
        "  # of the model's metrics at each epoch. \n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  return epochs, hist    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj3v5EKQFY8s",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e6640f4-5bfb-4a3d-a545-0d0eaf4d7f74"
      },
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.003\n",
        "epochs = 250\n",
        "batch_size = 32\n",
        "validation_split = 0.2\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, hist = train_model(my_model, x_train, y_train, epochs, batch_size, validation_split) \n",
        "\n",
        "# Plot a graph of the metric vs. epochs.\n",
        "list_of_metrics_to_plot = ['accuracy']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
        "\n",
        "# Evaluate against the test set.\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "loss,acc=my_model.evaluate(x=x_test, y=y_test, batch_size=batch_size) #x_train_normalized"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "25/25 [==============================] - 1s 11ms/step - loss: 0.9574 - accuracy: 0.5426 - val_loss: 0.7930 - val_accuracy: 0.6649\n",
            "Epoch 2/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.7471 - accuracy: 0.6615 - val_loss: 0.6366 - val_accuracy: 0.6959\n",
            "Epoch 3/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7442 - val_loss: 0.4951 - val_accuracy: 0.7887\n",
            "Epoch 4/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8411 - val_loss: 0.3857 - val_accuracy: 0.8351\n",
            "Epoch 5/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.9109 - val_loss: 0.3119 - val_accuracy: 0.8711\n",
            "Epoch 6/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 0.9251 - val_loss: 0.2668 - val_accuracy: 0.9175\n",
            "Epoch 7/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1529 - accuracy: 0.9444 - val_loss: 0.2858 - val_accuracy: 0.8918\n",
            "Epoch 8/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9574 - val_loss: 0.2592 - val_accuracy: 0.9124\n",
            "Epoch 9/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9599 - val_loss: 0.2436 - val_accuracy: 0.9227\n",
            "Epoch 10/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9703 - val_loss: 0.2541 - val_accuracy: 0.9175\n",
            "Epoch 11/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0832 - accuracy: 0.9703 - val_loss: 0.2252 - val_accuracy: 0.9278\n",
            "Epoch 12/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9793 - val_loss: 0.2074 - val_accuracy: 0.9330\n",
            "Epoch 13/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9819 - val_loss: 0.2101 - val_accuracy: 0.9433\n",
            "Epoch 14/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0847 - accuracy: 0.9716 - val_loss: 0.1984 - val_accuracy: 0.9227\n",
            "Epoch 15/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9819 - val_loss: 0.2779 - val_accuracy: 0.9227\n",
            "Epoch 16/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.2872 - val_accuracy: 0.9330\n",
            "Epoch 17/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9871 - val_loss: 0.2623 - val_accuracy: 0.9381\n",
            "Epoch 18/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9910 - val_loss: 0.2622 - val_accuracy: 0.9381\n",
            "Epoch 19/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9871 - val_loss: 0.2790 - val_accuracy: 0.9278\n",
            "Epoch 20/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9910 - val_loss: 0.3106 - val_accuracy: 0.9330\n",
            "Epoch 21/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9922 - val_loss: 0.3127 - val_accuracy: 0.9381\n",
            "Epoch 22/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9948 - val_loss: 0.2836 - val_accuracy: 0.9433\n",
            "Epoch 23/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.3242 - val_accuracy: 0.9485\n",
            "Epoch 24/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9910 - val_loss: 0.3353 - val_accuracy: 0.9278\n",
            "Epoch 25/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9884 - val_loss: 0.2952 - val_accuracy: 0.9433\n",
            "Epoch 26/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9922 - val_loss: 0.2846 - val_accuracy: 0.9278\n",
            "Epoch 27/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9910 - val_loss: 0.2603 - val_accuracy: 0.9381\n",
            "Epoch 28/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9961 - val_loss: 0.3008 - val_accuracy: 0.9381\n",
            "Epoch 29/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9961 - val_loss: 0.2763 - val_accuracy: 0.9485\n",
            "Epoch 30/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9948 - val_loss: 0.3475 - val_accuracy: 0.9330\n",
            "Epoch 31/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9935 - val_loss: 0.3478 - val_accuracy: 0.9381\n",
            "Epoch 32/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.2925 - val_accuracy: 0.9536\n",
            "Epoch 33/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.2951 - val_accuracy: 0.9381\n",
            "Epoch 34/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.3361 - val_accuracy: 0.9330\n",
            "Epoch 35/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9485\n",
            "Epoch 36/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.9381\n",
            "Epoch 37/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9987 - val_loss: 0.3491 - val_accuracy: 0.9330\n",
            "Epoch 38/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9381\n",
            "Epoch 39/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.3129 - val_accuracy: 0.9433\n",
            "Epoch 40/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.2775 - val_accuracy: 0.9536\n",
            "Epoch 41/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.3362 - val_accuracy: 0.9330\n",
            "Epoch 42/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9935 - val_loss: 0.4742 - val_accuracy: 0.9021\n",
            "Epoch 43/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9871 - val_loss: 0.3299 - val_accuracy: 0.9536\n",
            "Epoch 44/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9948 - val_loss: 0.4583 - val_accuracy: 0.9433\n",
            "Epoch 45/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9948 - val_loss: 0.4099 - val_accuracy: 0.9330\n",
            "Epoch 46/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.4019 - val_accuracy: 0.9330\n",
            "Epoch 47/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.4065 - val_accuracy: 0.9381\n",
            "Epoch 48/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.9433\n",
            "Epoch 49/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.9433\n",
            "Epoch 50/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.9381\n",
            "Epoch 51/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.4708 - val_accuracy: 0.9433\n",
            "Epoch 52/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.3389 - val_accuracy: 0.9433\n",
            "Epoch 53/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.3736 - val_accuracy: 0.9433\n",
            "Epoch 54/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.4125 - val_accuracy: 0.9278\n",
            "Epoch 55/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.4306 - val_accuracy: 0.9330\n",
            "Epoch 56/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.4416 - val_accuracy: 0.9330\n",
            "Epoch 57/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4113 - val_accuracy: 0.9381\n",
            "Epoch 58/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.3945 - val_accuracy: 0.9381\n",
            "Epoch 59/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.3904 - val_accuracy: 0.9433\n",
            "Epoch 60/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.4368 - val_accuracy: 0.9330\n",
            "Epoch 61/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9948 - val_loss: 0.4167 - val_accuracy: 0.9330\n",
            "Epoch 62/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.4314 - val_accuracy: 0.9330\n",
            "Epoch 63/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0874 - accuracy: 0.9832 - val_loss: 0.4509 - val_accuracy: 0.9175\n",
            "Epoch 64/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9858 - val_loss: 0.4153 - val_accuracy: 0.9072\n",
            "Epoch 65/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9935 - val_loss: 0.4697 - val_accuracy: 0.9227\n",
            "Epoch 66/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.3449 - val_accuracy: 0.9278\n",
            "Epoch 67/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9987 - val_loss: 0.4173 - val_accuracy: 0.9381\n",
            "Epoch 68/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.4071 - val_accuracy: 0.9485\n",
            "Epoch 69/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.3584 - val_accuracy: 0.9485\n",
            "Epoch 70/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9485\n",
            "Epoch 71/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3711 - val_accuracy: 0.9485\n",
            "Epoch 72/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3740 - val_accuracy: 0.9485\n",
            "Epoch 73/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9485\n",
            "Epoch 74/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.4186 - val_accuracy: 0.9485\n",
            "Epoch 75/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9485\n",
            "Epoch 76/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.9536\n",
            "Epoch 77/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.4652 - val_accuracy: 0.9536\n",
            "Epoch 78/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4500 - val_accuracy: 0.9588\n",
            "Epoch 79/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.9588\n",
            "Epoch 80/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9588\n",
            "Epoch 81/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.9536\n",
            "Epoch 82/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3892 - val_accuracy: 0.9536\n",
            "Epoch 83/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3872 - val_accuracy: 0.9485\n",
            "Epoch 84/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.3995 - val_accuracy: 0.9588\n",
            "Epoch 85/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.9588\n",
            "Epoch 86/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.9588\n",
            "Epoch 87/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4154 - val_accuracy: 0.9588\n",
            "Epoch 88/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9588\n",
            "Epoch 89/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.3990 - val_accuracy: 0.9536\n",
            "Epoch 90/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 8.0798e-04 - accuracy: 1.0000 - val_loss: 0.3844 - val_accuracy: 0.9588\n",
            "Epoch 91/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.9536\n",
            "Epoch 92/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9974 - val_loss: 0.3931 - val_accuracy: 0.9536\n",
            "Epoch 93/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 7.4080e-04 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9536\n",
            "Epoch 94/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9974 - val_loss: 0.4109 - val_accuracy: 0.9485\n",
            "Epoch 95/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9974 - val_loss: 0.4364 - val_accuracy: 0.9485\n",
            "Epoch 96/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9536\n",
            "Epoch 97/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 0.4848 - val_accuracy: 0.9536\n",
            "Epoch 98/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.4861 - val_accuracy: 0.9485\n",
            "Epoch 99/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.4908 - val_accuracy: 0.9485\n",
            "Epoch 100/250\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 0.6035 - val_accuracy: 0.9278\n",
            "Epoch 101/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9819 - val_loss: 0.5426 - val_accuracy: 0.9227\n",
            "Epoch 102/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9742 - val_loss: 0.3251 - val_accuracy: 0.9485\n",
            "Epoch 103/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1090 - accuracy: 0.9703 - val_loss: 0.3047 - val_accuracy: 0.9124\n",
            "Epoch 104/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9780 - val_loss: 0.2352 - val_accuracy: 0.9330\n",
            "Epoch 105/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9884 - val_loss: 0.1486 - val_accuracy: 0.9536\n",
            "Epoch 106/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9961 - val_loss: 0.1610 - val_accuracy: 0.9639\n",
            "Epoch 107/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9987 - val_loss: 0.1920 - val_accuracy: 0.9639\n",
            "Epoch 108/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.1972 - val_accuracy: 0.9588\n",
            "Epoch 109/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9536\n",
            "Epoch 110/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9536\n",
            "Epoch 111/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 0.2054 - val_accuracy: 0.9536\n",
            "Epoch 112/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9536\n",
            "Epoch 113/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.2122 - val_accuracy: 0.9588\n",
            "Epoch 114/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9639\n",
            "Epoch 115/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 0.2280 - val_accuracy: 0.9639\n",
            "Epoch 116/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9639\n",
            "Epoch 117/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9588\n",
            "Epoch 118/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9588\n",
            "Epoch 119/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9588\n",
            "Epoch 120/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9588\n",
            "Epoch 121/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9588\n",
            "Epoch 122/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9588\n",
            "Epoch 123/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9588\n",
            "Epoch 124/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8.4596e-04 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9588\n",
            "Epoch 125/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9588\n",
            "Epoch 126/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9588\n",
            "Epoch 127/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.2459 - val_accuracy: 0.9536\n",
            "Epoch 128/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.2428 - val_accuracy: 0.9588\n",
            "Epoch 129/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9588\n",
            "Epoch 130/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9536\n",
            "Epoch 131/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 0.2303 - val_accuracy: 0.9536\n",
            "Epoch 132/250\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9536\n",
            "Epoch 133/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.2342 - val_accuracy: 0.9536\n",
            "Epoch 134/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9974 - val_loss: 0.2395 - val_accuracy: 0.9536\n",
            "Epoch 135/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9536\n",
            "Epoch 136/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9536\n",
            "Epoch 137/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9536\n",
            "Epoch 138/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.2418 - val_accuracy: 0.9536\n",
            "Epoch 139/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9536\n",
            "Epoch 140/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4.3796e-04 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9536\n",
            "Epoch 141/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9536\n",
            "Epoch 142/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9536\n",
            "Epoch 143/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9536\n",
            "Epoch 144/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9.9782e-04 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9485\n",
            "Epoch 145/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9536\n",
            "Epoch 146/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 4.3905e-04 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9536\n",
            "Epoch 147/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9588\n",
            "Epoch 148/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9639\n",
            "Epoch 149/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9639\n",
            "Epoch 150/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9639\n",
            "Epoch 151/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9.0157e-04 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9639\n",
            "Epoch 152/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9691\n",
            "Epoch 153/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 3.3850e-04 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9691\n",
            "Epoch 154/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.2629 - val_accuracy: 0.9639\n",
            "Epoch 155/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 0.2800 - val_accuracy: 0.9691\n",
            "Epoch 156/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9691\n",
            "Epoch 157/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 0.2460 - val_accuracy: 0.9691\n",
            "Epoch 158/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9691\n",
            "Epoch 159/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 3.8190e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9691\n",
            "Epoch 160/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9691\n",
            "Epoch 161/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9742\n",
            "Epoch 162/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9.4570e-04 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9742\n",
            "Epoch 163/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.4008 - val_accuracy: 0.9691\n",
            "Epoch 164/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1556 - accuracy: 0.9767 - val_loss: 0.5392 - val_accuracy: 0.9381\n",
            "Epoch 165/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9806 - val_loss: 0.1335 - val_accuracy: 0.9381\n",
            "Epoch 166/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.1723 - val_accuracy: 0.9691\n",
            "Epoch 167/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1659 - val_accuracy: 0.9536\n",
            "Epoch 168/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9485\n",
            "Epoch 169/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9588\n",
            "Epoch 170/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9691\n",
            "Epoch 171/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9691\n",
            "Epoch 172/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9691\n",
            "Epoch 173/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9691\n",
            "Epoch 174/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9794\n",
            "Epoch 175/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9691\n",
            "Epoch 176/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9794\n",
            "Epoch 177/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9794\n",
            "Epoch 178/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9794\n",
            "Epoch 179/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9794\n",
            "Epoch 180/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.1502 - val_accuracy: 0.9691\n",
            "Epoch 181/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9639\n",
            "Epoch 182/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 0.9639\n",
            "Epoch 183/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 6.5281e-04 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9639\n",
            "Epoch 184/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9691\n",
            "Epoch 185/250\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.1779 - val_accuracy: 0.9691\n",
            "Epoch 186/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9691\n",
            "Epoch 187/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9691\n",
            "Epoch 188/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9691\n",
            "Epoch 189/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.0831e-04 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9691\n",
            "Epoch 190/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9691\n",
            "Epoch 191/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9691\n",
            "Epoch 192/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8.5269e-04 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9691\n",
            "Epoch 193/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9691\n",
            "Epoch 194/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 3.6575e-04 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9691\n",
            "Epoch 195/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8.5846e-04 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9691\n",
            "Epoch 196/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9.4625e-04 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9691\n",
            "Epoch 197/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9691\n",
            "Epoch 198/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9.2531e-04 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9691\n",
            "Epoch 199/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9794\n",
            "Epoch 200/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 6.6159e-04 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9794\n",
            "Epoch 201/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 3.1457e-04 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9794\n",
            "Epoch 202/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.7635e-04 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9794\n",
            "Epoch 203/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.1806 - val_accuracy: 0.9794\n",
            "Epoch 204/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9691\n",
            "Epoch 205/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9691\n",
            "Epoch 206/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 7.3165e-04 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9691\n",
            "Epoch 207/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.1696e-04 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9794\n",
            "Epoch 208/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.7924e-04 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9794\n",
            "Epoch 209/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9794\n",
            "Epoch 210/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 6.6712e-04 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9691\n",
            "Epoch 211/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 2.1879e-04 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9691\n",
            "Epoch 212/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 6.8012e-04 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9691\n",
            "Epoch 213/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 6.9151e-04 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9691\n",
            "Epoch 214/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9691\n",
            "Epoch 215/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9794\n",
            "Epoch 216/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 8.4947e-04 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9691\n",
            "Epoch 217/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9691\n",
            "Epoch 218/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9935 - val_loss: 0.1802 - val_accuracy: 0.9639\n",
            "Epoch 219/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9922 - val_loss: 0.2729 - val_accuracy: 0.9330\n",
            "Epoch 220/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.4100 - val_accuracy: 0.9330\n",
            "Epoch 221/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.3681 - val_accuracy: 0.9485\n",
            "Epoch 222/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.3283 - val_accuracy: 0.9485\n",
            "Epoch 223/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.9935 - val_loss: 0.5131 - val_accuracy: 0.9227\n",
            "Epoch 224/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9884 - val_loss: 0.3396 - val_accuracy: 0.9330\n",
            "Epoch 225/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.2852 - val_accuracy: 0.9639\n",
            "Epoch 226/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9987 - val_loss: 0.3022 - val_accuracy: 0.9433\n",
            "Epoch 227/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.3372 - val_accuracy: 0.9433\n",
            "Epoch 228/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.3180 - val_accuracy: 0.9485\n",
            "Epoch 229/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.3301 - val_accuracy: 0.9536\n",
            "Epoch 230/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9485\n",
            "Epoch 231/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 0.3383 - val_accuracy: 0.9485\n",
            "Epoch 232/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9485\n",
            "Epoch 233/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9536\n",
            "Epoch 234/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.9536\n",
            "Epoch 235/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3578 - val_accuracy: 0.9536\n",
            "Epoch 236/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9974 - val_loss: 0.3491 - val_accuracy: 0.9536\n",
            "Epoch 237/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5.5171e-04 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9588\n",
            "Epoch 238/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5.5462e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9536\n",
            "Epoch 239/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9536\n",
            "Epoch 240/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9.9615e-04 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9536\n",
            "Epoch 241/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9536\n",
            "Epoch 242/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.3812 - val_accuracy: 0.9536\n",
            "Epoch 243/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9536\n",
            "Epoch 244/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.3990 - val_accuracy: 0.9536\n",
            "Epoch 245/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.9536\n",
            "Epoch 246/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.9536\n",
            "Epoch 247/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9.4664e-04 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.9536\n",
            "Epoch 248/250\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 6.7035e-04 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.9536\n",
            "Epoch 249/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.9536\n",
            "Epoch 250/250\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.9536\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9711\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xnew = np.asanyarray([[0,21,4,1,1,5,3,5,2,3,3,4,2,4,2,5,3], [1,21,4,4,4,5,5,4,4,3,4,4,5,5,5,3,3]])\n",
        "# make a prediction\n",
        "from sklearn import preprocessing\n",
        "Xnew = preprocessing.StandardScaler().fit(Xnew).transform(Xnew)\n",
        "# std value = (x-myu)/sigma where myu is mean, sigma is variance\n",
        "\n",
        "ynew = my_model.predict(Xnew)\n",
        "predict_classes=np.argmax(ynew,axis=1)\n",
        "# show the inputs and predicted outputs\n",
        "print(\"X=%s, Predicted=%s\" % (Xnew[0], predict_classes[0]))\n",
        "print(\"X=%s, Predicted=%s\" % (Xnew[1], predict_classes[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOHekq2JAj9I",
        "outputId": "a4baeed1-b812-420e-fe2b-6d4baf885d04"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 103ms/step\n",
            "X=[-1.  0.  0. -1. -1.  0. -1.  1. -1.  0. -1.  0. -1. -1. -1.  1.  0.], Predicted=2\n",
            "X=[ 1.  0.  0.  1.  1.  0.  1. -1.  1.  0.  1.  0.  1.  1.  1. -1.  0.], Predicted=2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.save('/content/drive/MyDrive/Kodikon/saved_model/my_model.h5') \n"
      ],
      "metadata": {
        "id": "B8OyRHX3Nu6U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/Kodikon/saved_model/my_model.h5')\n",
        "\n",
        "loss,acc=new_model.evaluate(x=x_test, y=y_test, batch_size=batch_size)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aklmkECNvEI",
        "outputId": "45bd518f-9db3-4cf3-bf5d-4ff9cdc13897"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9711\n",
            "Restored model, accuracy: 97.11%\n"
          ]
        }
      ]
    }
  ]
}